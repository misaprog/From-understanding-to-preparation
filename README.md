# From-understanding-to-preparation

# データサイエンス方法論ラボ：理解から準備へ

## 🎯 目標

このラボを完了すると、以下ができるようになります：

- データを理解する  
- 分析や推論に向けてデータを準備する

---

## 🧭 はじめに

このラボでは、データサイエンス方法論の学習を継続し、特に以下の2つのステージに焦点を当てます：

- データ理解（Data Understanding）  
- データ準備（Data Preparation）

---

## 📑 目次

- Recap（前回のおさらい）
- データ理解（Data Understanding）
- データ準備（Data Preparation）

---

## 🔁 Recap（前回のおさらい）

前回のラボ「From Requirements to Collection（要件から収集へ）」では、**ビジネス理解ステージ**で導き出された問い：

> 「与えられたレシピの料理の種類（cuisine）を自動的に判別することは可能か？」

に対するデータがすでに存在することを確認しました。

研究者の **Yong-Yeol Ahn** 氏は、次の3つの異なるウェブサイトから、**数万件の料理レシピ（料理の種類と材料）**をスクレイピングしています：

- （以下、元のウェブサイト名やデータの内容が続く予定）

---

※このドキュメントはIBM Data Science Professional Certificate コースのラボ教材を参考に作成されています。

## 🧪 データの出典と補足情報

より詳しく **Yong-Yeol Ahn 氏と彼の研究**について知りたい場合は、彼の論文  
「Flavor Network and the Principles of Food Pairing（フレーバーネットワークと食材の組み合わせ原理）」を読むことをおすすめします。

このラボで使用するデータは、すでにIBMのサーバーにアップロードされており、すぐに利用できるようになっています。


## 🔍 研究の参考情報とデータの場所

Yong-Yeol Ahn 氏とその研究について詳しく知りたい方は、  
彼の論文「**Flavor Network and the Principles of Food Pairing**（フレーバーネットワークと食材の組み合わせの原則）」を読むことをおすすめします。

この研究では、世界中のさまざまな料理における食材の組み合わせパターンを分析しています。

📄 [論文はこちら（Nature誌）](https://www.nature.com/articles/srep00196)

また、私たちはこのラボで使用するデータをあらかじめ収集し、皆さんがすぐにアクセスできるように **IBMのサーバーに配置**しています。

> ⚠️ **重要な注意事項**

Python のプログラミング方法を理解している必要は **ありません**。  
以下に示すコードは、**データ収集のステージを説明するための例**として使用されており、コードの各行の意味がわからなくても問題ありません。

この認定プログラムを修了することを選択すれば、  
後半で **「Python for Data Science」** という完全な Python プログラミングコースを受講でき、  
Python の使い方を学ぶことができます。

---

## Python バージョンの確認（Jupyter Notebook用）

Jupyter Notebook 上で Python のバージョンを確認するには、以下のようにします。

```python
# ローカル環境で実行している場合に、Pythonのバージョンを表示するコマンド
!python -V

```
---

解説
!（ビックリマーク）は、Jupyter Notebookでシェルコマンド（端末コマンド）を実行するための記号です。

python -V は、Pythonのバージョン情報を表示する標準的なコマンドです。

つまり、このセルを実行すると、インストールされているPythonのバージョンが表示されます。

ローカル環境だけでなく、クラウド上のJupyter環境でも使えます。

---

Pythonバージョンを確認する他の方法として、Pythonコードで直接取得することもできます：

```

import sys
print(sys.version)

```

---

## 必要なライブラリのインポート

このプロジェクトでは、以下の Python ライブラリを使用します。

```python
import pandas as pd  # pandas: データ解析・操作用のライブラリ（DataFrameなどを使う）
pd.set_option('display.max_columns', None)  # 表示される列数の上限を解除（すべての列を表示）

import numpy as np  # numpy: 数値計算ライブラリ（配列処理、数学関数などに利用）

import re  # re: 正規表現を使った文字列検索や置換などに使用

```

補足
pandas は表形式のデータ（CSVなど）の読み込み・加工に使います。

numpy は数値計算を効率的に行うためのライブラリで、機械学習や統計処理にも必須です。

re は、データの中の特定パターンを抽出・加工するための文字列操作ツールです。

pd.set_option('display.max_columns', None) は、Notebook上で列が多いデータでもすべて表示できるようにする設定です。

---

## データの読み込み1

IBMのサーバーからレシピデータをダウンロードし、`pandas` のデータフレームに読み込みます。  
この処理によって、後の分析や前処理がしやすくなります。

---
## データの読み込み2

クラウド環境（例：IBM Skills Network Labs や Google Colab）で実行する場合、以下のコードを使用して IBM のサーバーからレシピデータをダウンロードし、pandasのデータフレームに読み込みます。

```python
recipes = pd.read_csv("https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DS0103EN-SkillsNetwork/labs/Module%202/recipes.csv")

print("Data read into dataframe!")  # 読み込みには約30秒かかります
```
ローカル環境で実行する場合は、あらかじめファイルをダウンロードして同じフォルダに置き、コメントアウトを外して実行してください。

```

# recipes = pd.read_csv("recipes.csv")

```
## データの読み込み（ローカル環境 / 通常のJupyter Notebook向け）

以下のコードは、IBMのクラウドストレージからCSVデータを `pandas` で直接取得し、データフレームに読み込む方法です。

```python
import pandas as pd

url = "https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DS0103EN-SkillsNetwork/labs/Module%202/recipes.csv"

recipes = pd.read_csv(url)

print("Data read into dataframe!")
```
| チェック項目                    | 状況            |
| ------------------------- | ------------- |
| データの読み込み（`read_csv`）      | ✅ 成功          |
| DataFrame の先頭表示（`head()`） | ✅ 確認済み        |
| データの構造確認（`shape`）         | ✅ 行数・列数が確認できた |
| 列名確認（`columns`）           | ✅ 確認済み        |
---
#### 私たちのデータセットは57,691件のレシピで構成されています。各行はレシピを表し、各レシピには対応する料理名と、アーモンドからズッキーニまで384種類の材料がレシピに含まれているかどうかが記録されています。
---
##### 基本的な寿司レシピには、以下の材料が含まれていることはご存知でしょう。

米
醤油
わさび
魚介類/野菜

---
#### これらの材料がデータフレームに存在するかどうか確認してみましょう
---
このコードは正規表現（re.compile(...)）を用いて、レシピデータに含まれる材料（列名）の中から、「rice」「wasabi」「soy」を名前に含む食材を検索しています。材料データが数百種類ある中から、関係のある食材のみをピックアップするための方法です。

#### これは 特徴量の選定（feature selection） や、データ探索（exploratory analysis） の一環として行われます。
---
#### 材料リストから、特定のキーワード（rice, wasabi, soy）を含む列名（材料）を検索
#### これは、正規表現を用いて材料名の中にキーワードが含まれるかをチェックする操作です。
#### このような探索は、特定の料理に特徴的な食材を確認する際に有用です。
---
['brown_rice', 'licorice', 'rice']
「rice」を含む材料が以下の3つ見つかっています：

brown_rice（玄米）

licorice（リコリス：英単語に"rice"が含まれているだけ）

rice（白米）

※ licorice は rice とは関係ないので、「rice」という単語の部分一致による**副作用（ノイズ）**ですね。
これは正規表現で .*(rice).* としているため、「rice」がどこに現れてもヒットしてしまうためです。

['wasabi']
「wasabi」にぴったり一致する列が1つ見つかっています。

['soy_sauce', 'soybean', 'soybean_oil']
「soy」を含む材料が3つ見つかっています：

soy_sauce（醤油）

soybean（大豆）

soybean_oil（大豆油）

#### → これは非常に有効な特徴量になりそうですね。
---
### このステップの意味（まとめ）

このような特徴語（rice, soy, wasabiなど）を材料データの中から抽出することで：

特定の料理（例：日本料理）に関連する材料を分析できる

モデルに使う重要な**特徴量（features）**の候補を見つける

データの中身を把握し、モデリングの方向性を考えるヒントになる

というような効果があります。

---
#### 材料データ（列名）の中から、「rice」「wasabi」「soy」を含む食材を抽出
#### 正規表現により部分一致で検索しているため、「licorice」のように一部に"rice"が含まれるものもヒットする
#### この操作により、特定の料理に特徴的な材料を特定することができる
---

### データ準備

このセクションでは、データサイエンス手法の次の段階であるモデリングに向けてデータを準備します。この段階では、データをさらに詳しく調査し、分析アプローチの段階で選択した機械学習アルゴリズム（決定木）に適した形式になっていることを確認します。

#### まず、データを調べて、クリーニングが必要かどうかを確認します。
---
データフレームの最初の5行を表示して、

列名や内容の異常（例えば「Country」が「cuisine」列の代わりになってるなど）を目視で確認できます。

---
上記の表を見ると、以下の点が分かります。


料理の列に「国」というラベルが付けられていますが、これは正確ではありません。

料理名が統一されておらず、すべての料理の頭文字が大文字で始まるわけではありません。

一部の料理は、国名のバリエーションとして重複しています（ベトナムとベトナム語など）。

一部の料理にはレシピがほとんどありません

---
これらの問題を修正しましょう。

#### （１）料理を表示する列の名前を修正します。

 #### Explanation
 
recipes.columns.values で、現在の列名（カラム名）の一覧を取得します。

最初の列（column_names[0]）は「国名（例: Japan）」を表すものでしたが、これは料理の種類を示しているため、"cuisine" に変更します。

新しいカラム名のリストを recipes.columns に再代入して、データフレームに反映させます。

---
#### （2）料理名はすべて小文字にしてください。
---
#### （3）料理名に一貫性を持たせます。
---
#### （4）料理名の標準化

データセット内の一部の料理のラベルは一貫性がなく、標準的な料理名ではなく国名に基づいています。

類似または同一の料理が正しくグループ化されるように、ラベルを整理して標準化します。

 #### Explanation
 
.loc[] を使って、条件に一致する行の cuisine を別の値に置き換えています。

例えば "austria" を "austrian" に変換することで、「国名」→「料理名」に変換しています。

"spain" と "portugal" は料理が似ているため、どちらも "spanish_portuguese" に統一しています。

"uk-and-ireland" と "irish" も "uk-and-irish" にまとめて統一しています。

このように、重複や表記のブレを統一することで、モデルに正しい情報を渡しやすくなります。

---
#### （５）レシピが 50 件未満の料理を削除します。

#### 解説：
value_counts()：cuisineごとのレシピ数をカウントします。

cuisine_counts >= 50：50件以上の料理だけを残します。

.index：条件を満たしたcuisine名（インデックス）だけを抽出。

この変数 cuisines_to_keep を使って、次のフィルター処理（すでに記入済み）で不要な料理を取り除いています。

---
#### (6) 削除後の行数の変化を確認する
```
rows_before = recipes.shape[0]  # number of rows of original dataframe
```
recipes.shape[0] は、データフレームの行数を取得します。

つまり、削除前の総レシピ数を rows_before に保存しています。
```
print("Number of rows of original dataframe is {}.".format(rows_before))
```
1行目で取得した行数を表示します。
```
recipes = recipes.loc[recipes['cuisine'].isin(cuisines_to_keep)]
```
recipes['cuisine'].isin(cuisines_to_keep) は、料理カテゴリが「50件以上あるもの」に該当する行だけを取り出すフィルターです。

recipes.loc[...] でその行を抽出し、元の recipes に上書きしています。

これで、少ないレシピ（50件未満）の料理は除外されました。
```
rows_after = recipes.shape[0]  # number of rows of processed dataframe
```
除外処理が終わった後の、**残った行数（レシピ数）**を取得しています
```
print("Number of rows of processed dataframe is {}.".format(rows_after))
```
フィルター後の行数を表示します。
```
print("{} rows removed!".format(rows_before - rows_after))
```
**削除された行数（レシピ数）**を表示します。

元の行数 - 処理後の行数 を計算し、何件削除されたかを出力しています

--- 
#### 補足：どんな時に使うの？

機械学習においては、極端に少ないデータは学習の妨げになります。

このようにして、「十分な数がある料理カテゴリ」のみに絞り、偏りの少ない、バランスの取れたデータセットにしていきます。

---
#### (7) すべての「はい」を1に、「いいえ」を0に変換する

---
### データをより深く理解し、興味深い予備的な観察結果を記録するため、もう少しデータを分析してみましょう。

次のセルを実行すると、米、醤油、わさび、海藻を含むレシピが表示されます。

---
上記のコードの結果に基づいて、米、醤油、わさび、海藻を含むすべてのレシピを日本料理として分類できますか？なぜですか？

#正解は：

いいえ。アジア料理や東アジア料理などの他のレシピにもこれらの材料が含まれているためです。

---
#### (8) すべてのレシピの材料を数えてみましょう

iloc[:, 1:] は すべての行（:）の2列目以降（1:） を取得

1: とすることで、cuisine 列は除外（材料だけを対象）

各列ごとに（＝各材料ごとに）合計を計算

axis=0 は「縦方向に足す（列ごとの合計）」

結果の変数：ing

このような 材料名とその使用回数の一覧 が得られます：
```
salt         15000
sugar        12000
soy_sauce     8000
...
dtype: int64
```
---
#### (9) 材料（ingredient）とその使用回数（count）をもとに データフレーム ing_df を作る処理

 1. 材料名のシリーズを作る：
```
 ingredient = pd.Series(ing.index.values, index = np.arange(len(ing)))
```  
ing は .sum(axis=0) で計算された 材料ごとの合計使用回数 を持つ Series（pandasの1列のデータ）です。

ing.index.values → 材料名の配列（例：["salt", "sugar", "water", ...]）

np.arange(len(ing)) → インデックスとして [0, 1, 2, ...] を作る

つまり、👉 材料名だけをSeriesとして取り出している、ということです。


2. 使用回数のシリーズを作る：
```
count = pd.Series(list(ing), index = np.arange(len(ing)))
```
list(ing) → 材料の使用回数のリストに変換

同じくインデックスは [0, 1, 2, ...]  👉 材料の使用回数をSeriesとして定義しています。


3. データフレームを作る：
```
ing_df = pd.DataFrame(dict(ingredient = ingredient, count = count))
```
2つのSeriesを使って、ingredient と count という列を持つ DataFrame を作成。

dict()で列名を指定しています。


4. 列の順番を明示的に指定：
```
ing_df = ing_df[["ingredient", "count"]]
```
念のため、列の順番を ingredient → count に整えています。


5. 全行を表示：
```
print(ing_df.to_string())
```
to_string() を使うと、Jupyter Notebook でも省略されずに すべての行が表示されます。

| 処理内容         | 意味                      |
| ------------ | ----------------------- |
| `ingredient` | 材料名のリストをSeriesに変換       |
| `count`      | 使用回数のリストをSeriesに変換      |
| `ing_df`     | 材料と回数を持つ表（DataFrame）を作る |
| `print()`    | 中身を全部表示                 |

---
#### これで、すべてのレシピの材料とその合計数のデータフレームができました。このデータフレームを降順で並べ替えてみましょう。

 1. 材料を使用回数の 多い順に並び替える
```
ing_df.sort_values(["count"], ascending=False, inplace=True)
```
sort_values() は、指定した列に基づいて 並び替えをします。

["count"] → 並び替えの基準は「使用回数の列」

ascending=False → 降順（＝多い順）で並べます

inplace=True → 元の ing_df を直接上書きします（新しい変数にしない）

💡 結果：材料が「よく使われる順」に並び替えられます。


2. インデックス（行番号）を振り直す
```
ing_df.reset_index(inplace=True, drop=True)
```
並び替え後、インデックスが元のままだと 0, 13, 21, ... みたいにバラバラになります。

それを 0, 1, 2, ... の 連番にリセットします。

drop=True にすると、古いインデックスは削除されて、DataFrameに追加されません。

💡 結果：表がきれいに表示されるようになります。


3. 表の中身を表示
```
print(ing_df)
```
print() で、並び替えてリセットされた ing_df を表示。

| 処理               | 内容         | 目的             |
| ---------------- | ---------- | -------------- |
| `.sort_values()` | 使用回数で並び替え  | 使用頻度の高い材料を上に表示 |
| `.reset_index()` | インデックス振り直し | 表を見やすく整える      |
| `print()`        | 表示         | 結果確認           |

---
#### 最も人気のある3つの食材は何ですか?

1. 卵は21,025回出現しています。
2. 小麦は20,781回出現しています。
3. バターは20,719回出現しています。

---

しかし、上記の表には問題があることに注意してください。データセットには約4万件のアメリカ料理のレシピが含まれており、データがアメリカ産の食材に偏っていることを意味します。

そこで、料理ごとの食材に注目することで、より客観的な食材の概要を計算してみましょう。

それぞれの料理のプロファイルを作成しましょう。

つまり、中国人が一般的にどのような食材を使用しているか、そして例えばカナダ料理とはどのようなものかを調べてみましょう。

---
#### 解説

🔹 recipes.groupby("cuisine")

データを 「cuisine（料理ジャンル）」でグループ化します。

たとえば「japanese」「italian」「mexican」などでグループに分ける。

🔹 .mean()

グループごとに 数値データの平均を計算します。

このデータでは材料（ingredient）が0か1で記録されているので、

平均をとることで「その料理ジャンルで材料がどれくらい使われているか」がわかります。

📌 たとえば：

salt の値が 0.85 → その料理に 85%のレシピで使われている

tofu の値が 0.10 → その料理に 10%のレシピで使われている

🔹 .head()

最初の5行を表示します（確認用）。

---

上記のように、各行が料理、各列（最初の列を除く）が食材を表すデータフレームを作成しました。行の値は、対応する料理における各食材の割合を表しています。

例：

アーモンドは、アフリカ料理のレシピ全体の15.65%に含まれています。

バターは、カナダ料理のレシピ全体の38.11%に含まれています。

各料理の上位4つの食材を表示して、各料理のプロファイルを出力してみましょう。

---
### cuisines データフレーム（料理ジャンルごとの材料使用平均）から、各ジャンルで最もよく使われる材料トップ4を表示する。

####  コード詳細解説
```
num_ingredients = 4
```
 表示したい「上位の材料数」を指定。
 
 ここでは **トップ4** の材料を表示するようにしています
```
def print_top_ingredients(row):
```
row には cuisines データフレームの 1行（＝1料理ジャンル） が渡されます。

そのジャンルで使われている材料の使用率（0.0～1.0）が入っています。
```
print(row.name.upper())
```
行（料理ジャンル）の名前を **大文字で表示**。

例: `"italian"` → `ITALIAN`
```
row_sorted = row.sort_values(ascending=False)*100
```
材料を 使用頻度の高い順にソート。

* 100 でパーセント表記にします（例: 0.87 → 87.0）
```
top_ingredients = list(row_sorted.index.values)[0:num_ingredients]
row_sorted = list(row_sorted)[0:num_ingredients]
```
トップ4の材料名（`index`）と、その使用率（`values`）を取得。
```
for ind, ingredient in enumerate(top_ingredients):
        print("%s (%d%%)" % (ingredient, row_sorted[ind]), end=' ')
    print("\n")
```
材料名と使用率を表示。

例: garlic (87%) salt (79%) olive_oil (73%) tomato (69%)
```
create_cuisines_profiles = cuisines.apply(print_top_ingredients, axis=1)
```
cuisines` の各行（各料理ジャンル）に対して、先ほどの関数 `print_top_ingredients` を適用。

 `axis=1` → 行方向に関数を適用。


それぞれの料理ジャンルの**特徴的な材料**がすぐに把握できる。

データの理解（EDA: Exploratory Data Analysis）の一環。

このあとに使う分類モデルなどに役立つ知見を得るため

---
#### この時点で、データを十分に理解でき、データの準備が整って、モデリングに適した形式になっていると感じています。

---
